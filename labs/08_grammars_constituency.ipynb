{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Constituency Grammars with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Understanding: \n",
    "    - relation between grammar and syntactic parse tree\n",
    "    - relation between grammar and syntactic categories\n",
    "    - relation between grammar and Part-of-Speech tags\n",
    "    - context free grammars (CFG)\n",
    "    - probabilistic context free grammars (PCFG)\n",
    "- Learning how to:\n",
    "    - define CFG in NLTK\n",
    "    - parse with CFG\n",
    "    - learn PCFGs from a treebank\n",
    "    - parse with PCFG\n",
    "    - generate sentences using a grammar in NLTK\n",
    "    - evaluate parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended Reading\n",
    "- Dan Jurafsky and James H. Martin. [__Speech and Language Processing__ (SLP)](https://web.stanford.edu/~jurafsky/slp3/) (3rd ed. draft)\n",
    "- Steven Bird, Ewan Klein, and Edward Loper. [__Natural Language Processing with Python__ (NLTK)](https://www.nltk.org/book/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covered Material\n",
    "- SLP\n",
    "    - [Chapter 17: Context-Free Grammars and Constituency Parsing](https://web.stanford.edu/~jurafsky/slp3/17.pdf)\n",
    "- NLTK \n",
    "    - [Chapter 8: Analyzing Sentence Structure](https://www.nltk.org/book/ch08.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Requirements\n",
    "\n",
    "- [NLTK](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grammars, Production Rules, and Parse Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linguistics, [**syntax**](https://en.wikipedia.org/wiki/Syntax) is the study of how words and morphemes combine to form larger units such as phrases and sentences. Central concerns of syntax include word order, **grammatical relations**, **hierarchical sentence structure** (constituency), agreement, the nature of cross-linguistic variation, and the relationship between form and meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linguistics, the [**grammar**](https://en.wikipedia.org/wiki/Grammar) of a natural language is its set of structural constraints on speakers' or writers' composition of clauses, phrases, and words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [**context-free grammar (CFG)**](https://en.wikipedia.org/wiki/Context-free_grammar) is a formal grammar whose [**production rules**](https://en.wikipedia.org/wiki/Production_(computer_science)) are of the form:\n",
    "\n",
    "$$A \\to \\alpha$$\n",
    "\n",
    "where: \n",
    "- $A$ a single non-terminal symbol\n",
    "- $\\alpha$  a string of terminals and/or non-terminals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Parsing**](https://en.wikipedia.org/wiki/Parsing), syntax analysis, or syntactic analysis is the process of analyzing a string of symbols, either in natural language, computer languages or data structures, conforming to the rules of a formal grammar. \n",
    "Within computational linguistics the term is used to refer to the formal analysis by a computer of a sentence or other string of words into its **constituents**, resulting in a **parse tree** showing their syntactic relation to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [**parse tree**](https://en.wikipedia.org/wiki/Parse_tree) or **parsing tree** or **derivation tree** or **concrete syntax tree** is an ordered, rooted tree that represents the syntactic structure of a string according to some **context-free grammar**. The term parse tree itself is used primarily in computational linguistics; in theoretical syntax, the term syntax tree is more common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Parse Tree Representation\n",
    "One of the possible parse trees for a sentence `I saw the man with a telescope` is as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "      S                                    \n",
    "  ____|___________                          \n",
    " |                VP                       \n",
    " |     ___________|________                 \n",
    " |    |       |            PP              \n",
    " |    |       |        ____|___             \n",
    " NP   |       NP      |        NP          \n",
    " |    |    ___|___    |     ___|______      \n",
    "PRON  V  Det      N   P   Det         N    \n",
    " |    |   |       |   |    |          |     \n",
    " I   saw the     man with  a      telescope\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To occupy less space, a parse tree is usually represented using \"bracketed expressions\", where brackets enclose each **constituent** and the first element of the expression is the tree-node label.\n",
    "\n",
    "```\n",
    "(S\n",
    "  (NP (PRON I))\n",
    "  (VP\n",
    "    (V saw)\n",
    "    (NP (Det the) (N man))\n",
    "    (PP (P with) (NP (Det a) (N telescope)))))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common to write a parse tree in a less readable one-line expression:\n",
    "\n",
    "```\n",
    "(S (NP (PRON I)) (VP (V saw) (NP (Det the) (N man)) (PP (P with) (NP (Det a) (N telescope)))))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Parse Trees in NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK provides `Tree` class for representing hierarchical language structures. The class implements many useful methods. <br> Full documentation [HERE](https://www.nltk.org/api/nltk.tree.tree.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. \"Core\" Methods\n",
    "\n",
    "- `fromstring()` reads a bracketed tree string and return the resulting tree\n",
    "\n",
    "- `productions()` generate the productions that correspond to the non-terminal nodes of the tree.\n",
    "    - For each subtree of the form `(P: C1 C2 ... Cn)` this produces a production of the form `P -> C1 C2 ... Cn`.\n",
    "\n",
    "- `label()` returns the node label of the tree\n",
    "\n",
    "- `subtrees()` generates all the subtrees of this tree\n",
    "\n",
    "- `pos()` return a sequence of pos-tagged words extracted from the tree.\n",
    "\n",
    "- `leaves()` returns the leaves of the tree.\n",
    "\n",
    "- `flatten()` return a flat version of the tree, with all non-root non-terminals removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tree import Tree\n",
    "sent = \"I saw the man with a telescope\"\n",
    "parse_tree_str = \"(S (NP (PRON I)) (VP (V saw) (NP (Det the) (N man)) (PP (P with) (NP (Det a) (N telescope)))))\"\n",
    "\n",
    "tree = Tree.fromstring(parse_tree_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (PRON I))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det the) (N man))\n",
      "    (PP (P with) (NP (Det a) (N telescope)))))\n"
     ]
    }
   ],
   "source": [
    "# prints bracketed expression for the parse tree\n",
    "print(tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "(S\n",
      "  (NP (PRON I))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det the) (N man))\n",
      "    (PP (P with) (NP (Det a) (N telescope)))))\n",
      "-----------------------------------------------------------------------------------------\n",
      "(NP (PRON I))\n",
      "-----------------------------------------------------------------------------------------\n",
      "(PRON I)\n",
      "-----------------------------------------------------------------------------------------\n",
      "(VP\n",
      "  (V saw)\n",
      "  (NP (Det the) (N man))\n",
      "  (PP (P with) (NP (Det a) (N telescope))))\n",
      "-----------------------------------------------------------------------------------------\n",
      "(V saw)\n",
      "-----------------------------------------------------------------------------------------\n",
      "(NP (Det the) (N man))\n",
      "-----------------------------------------------------------------------------------------\n",
      "(Det the)\n",
      "-----------------------------------------------------------------------------------------\n",
      "(N man)\n",
      "-----------------------------------------------------------------------------------------\n",
      "(PP (P with) (NP (Det a) (N telescope)))\n",
      "-----------------------------------------------------------------------------------------\n",
      "(P with)\n",
      "-----------------------------------------------------------------------------------------\n",
      "(NP (Det a) (N telescope))\n",
      "-----------------------------------------------------------------------------------------\n",
      "(Det a)\n",
      "-----------------------------------------------------------------------------------------\n",
      "(N telescope)\n"
     ]
    }
   ],
   "source": [
    "# prints all the subtrees\n",
    "for stree in tree.subtrees():\n",
    "    print('-'*89)\n",
    "    print(stree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Visualizaing Parse Trees\n",
    "\n",
    "In the code above, we have printed the parse tree using `print()` method, which prints a _bracketed expression_ tree.\n",
    "It is also possible to visualize syntactic trees of using other method: \n",
    "\n",
    "- `pprint()` the same as above\n",
    "- `pretty_print()` draws ASCII tree (the original example)\n",
    "- `draw()` opens a new window containing a graphical diagram of this tree.\n",
    "- `tree` a call to a tree draws it using `svgling` \n",
    "    - requires `svgling` module to be installed (`pip install svgling`)\n",
    "    - GitHub https://github.com/rawlins/svgling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         S                                                         \n",
      " ┌───────┴────────────────────┐                                        \n",
      " │                            VP                                   \n",
      " │       ┌─────────────┬──────┴──────────────┐                         \n",
      " │       │             │                     PP                    \n",
      " │       │             │             ┌───────┴──────┐                  \n",
      " NP      │             NP            │              NP             \n",
      " │       │      ┌──────┴──────┐      │       ┌──────┴─────────┐        \n",
      "PRON     V     Det            N      P      Det               N    \n",
      " │       │      │             │      │       │                │        \n",
      " I      saw    the           man    with     a            telescope\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tree\n",
    "print(tree.pretty_print(unicodelines=True, nodedist=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (PRON I))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det the) (N man))\n",
      "    (PP (P with) (NP (Det a) (N telescope)))))\n",
      "None\n",
      "      S                                    \n",
      "  ____|___________                          \n",
      " |                VP                       \n",
      " |     ___________|________                 \n",
      " |    |       |            PP              \n",
      " |    |       |        ____|___             \n",
      " NP   |       NP      |        NP          \n",
      " |    |    ___|___    |     ___|______      \n",
      "PRON  V  Det      N   P   Det         N    \n",
      " |    |   |       |   |    |          |     \n",
      " I   saw the     man with  a      telescope\n",
      "\n",
      "None\n",
      "         S                                                         \n",
      " ┌───────┴────────────────────┐                                        \n",
      " │                            VP                                   \n",
      " │       ┌─────────────┬──────┴──────────────┐                         \n",
      " │       │             │                     PP                    \n",
      " │       │             │             ┌───────┴──────┐                  \n",
      " NP      │             NP            │              NP             \n",
      " │       │      ┌──────┴──────┐      │       ┌──────┴─────────┐        \n",
      "PRON     V     Det            N      P      Det               N    \n",
      " │       │      │             │      │       │                │        \n",
      " I      saw    the           man    with     a            telescope\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(tree.pprint())\n",
    "print(tree.pretty_print()) # or\n",
    "print(tree.pretty_print(unicodelines=True, nodedist=4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Familiarize with the [`Tree`](https://www.nltk.org/api/nltk.tree.tree.html) class.\n",
    "\n",
    "- Consult the documentation for more detail (and other methods)\n",
    "- Try each of the \"core\" methods listed above\n",
    "    - see production rules, leaves, and pos\n",
    "\n",
    "#####   \"Core\" Methods\n",
    "\n",
    "- `fromstring()` reads a bracketed tree string and return the resulting tree\n",
    "\n",
    "- `productions()` generate the productions that correspond to the non-terminal nodes of the tree.\n",
    "    - For each subtree of the form `(P: C1 C2 ... Cn)` this produces a production of the form `P -> C1 C2 ... Cn`.\n",
    "\n",
    "- `label()` returns the node label of the tree\n",
    "\n",
    "- `subtrees()` generates all the subtrees of this tree\n",
    "\n",
    "- `pos()` return a sequence of pos-tagged words extracted from the tree.\n",
    "\n",
    "- `leaves()` returns the leaves of the tree.\n",
    "\n",
    "- `flatten()` return a flat version of the tree, with all non-root non-terminals removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Productions:\n",
      "[S -> NP VP,\n",
      " NP -> PRON,\n",
      " PRON -> 'I',\n",
      " VP -> V NP PP,\n",
      " V -> 'saw',\n",
      " NP -> Det N,\n",
      " Det -> 'the',\n",
      " N -> 'man',\n",
      " PP -> P NP,\n",
      " P -> 'with',\n",
      " NP -> Det N,\n",
      " Det -> 'a',\n",
      " N -> 'telescope']\n",
      "Label: VP\n",
      "Pos Tags: [('I', 'PRON'), ('saw', 'V'), ('the', 'Det'), ('man', 'N'), ('with', 'P'), ('a', 'Det'), ('telescope', 'N')]\n",
      "Leaves: ['I', 'saw', 'the', 'man', 'with', 'a', 'telescope']\n",
      "Flatten: (S I saw the man with a telescope)\n"
     ]
    }
   ],
   "source": [
    "# Productions\n",
    "print('Productions:')\n",
    "pprint(tree.productions())\n",
    "\n",
    "# Label\n",
    "print('Label:',tree[1].label() )\n",
    "\n",
    "# Pos tags\n",
    "print('Pos Tags:', tree.pos())\n",
    "\n",
    "# Leaves \n",
    "print('Leaves:', tree.leaves())\n",
    "\n",
    "# Flatten\n",
    "print('Flatten:', tree.flatten() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Context Free Grammars (CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1. Defining Context Free Grammars\n",
    "\n",
    "CFG are defined by a *start symbol* and a set of *production rules*. The *start symbol* defines the root node of parse trees (usually __S__). \n",
    "\n",
    "*Production rules* specify allowed parent-child relations in a parse tree. Each production specifies what node can be the parent of a particular set of children nodes. \n",
    "\n",
    "For example, the production `S -> NP VP` specifies that an `S` node can be the parent of an `NP` node and a `VP` node.\n",
    "\n",
    "The left-hand side of a production rules specifies potential *non-terminal* parent nodes; while right-hand side specifies list of allowed *non-terminal* and *terminal* (text) children. \n",
    "\n",
    "A production like `VP -> V NP | VP PP` has a disjunction on the right-hand side, shown by the `|` and is an abbreviation for the two productions `VP -> V NP` and `VP -> V NP PP`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2.1.1 Syntactic Categories\n",
    "\n",
    "| __Symbol__ | __Meaning__ | __Example__ |\n",
    "|:-----------|:------------|:------------|\n",
    "| S   | sentence             | I saw the man |\n",
    "| NP  | noun phrase          | the man | \n",
    "| VP  | verb phrase          | saw the man |\n",
    "| PP  | prepositional phrase | with a telescope |\n",
    "| Det | determiner  | the |\n",
    "| N   | noun        | man |\n",
    "| V   | verb        | saw |\n",
    "| P   | preposition | with |\n",
    "\n",
    "\n",
    "- Non-Terminals: `S`, `NP`, `VP`, `PP`\n",
    "- Pre-Terminals: `Det`, `N`, `V`, `P` (Part-of-Speech Tags)\n",
    "- Terminals (Leaves): the, man, saw, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.2. Defining Context Free Grammars in NLTK\n",
    "\n",
    "The grammar can be defined as a string or as a list of strings of production rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 14 productions (start state = S)\n",
      "    S -> NP VP\n",
      "    NP -> Det N\n",
      "    NP -> Det N PP\n",
      "    NP -> PRON\n",
      "    VP -> V NP\n",
      "    VP -> V NP PP\n",
      "    PP -> P NP\n",
      "    Det -> 'the'\n",
      "    Det -> 'a'\n",
      "    N -> 'man'\n",
      "    N -> 'telescope'\n",
      "    PRON -> 'I'\n",
      "    V -> 'saw'\n",
      "    P -> 'with'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "rules = [\n",
    "    'S -> NP VP',\n",
    "    'NP -> Det N | Det N PP | PRON',\n",
    "    'VP -> V NP | V NP PP',\n",
    "    'PP -> P NP',\n",
    "    'Det -> \"the\" | \"a\"',\n",
    "    'N -> \"man\" | \"telescope\"',\n",
    "    'PRON -> \"I\"',\n",
    "    'V -> \"saw\"',\n",
    "    'P -> \"with\"'   \n",
    "]\n",
    "\n",
    "toy_grammar = nltk.CFG.fromstring(rules)\n",
    "\n",
    "print(toy_grammar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Grammar object has 2 components:\n",
    "- start symbol\n",
    "- production rules\n",
    "\n",
    "Those can be access as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n"
     ]
    }
   ],
   "source": [
    "print(toy_grammar.start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S -> NP VP, NP -> Det N, NP -> Det N PP, NP -> PRON, VP -> V NP, VP -> V NP PP, PP -> P NP, Det -> 'the', Det -> 'a', N -> 'man', N -> 'telescope', PRON -> 'I', V -> 'saw', P -> 'with']\n"
     ]
    }
   ],
   "source": [
    "print(toy_grammar.productions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Each production has 2 parts:\n",
    "- left-hand side\n",
    "- right-hand side\n",
    "\n",
    "which can be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "(NP, VP)\n"
     ]
    }
   ],
   "source": [
    "rule = toy_grammar.productions()[0]\n",
    "print(rule.lhs())\n",
    "print(rule.rhs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Grammar__'s `productions(lhs=None, rhs=None, empty=False)` methos returns the grammar productions, filtered by the left-hand side or the first item in the right-hand side.\n",
    "\n",
    "__Parameters__\n",
    "- `lhs` -- Only return productions with the given left-hand side.\n",
    "- `rhs` -- Only return productions with the given first item in the right-hand side.\n",
    "- `empty` -- Only return productions with an empty right-hand side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NP -> Det N, NP -> Det N PP, NP -> PRON]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import Nonterminal\n",
    "toy_grammar.productions(lhs=Nonterminal('NP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> NP VP]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_grammar.productions(rhs=Nonterminal('NP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_grammar.productions(empty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3. Parsing with CFG\n",
    "\n",
    "> A parser processes input sentences according to the productions of a grammar, and builds one or more constituent structures that conform to the grammar. A grammar is a declarative specification of well-formedness — it is actually just a string, not a program. A parser is a procedural interpretation of the grammar. It searches through the space of trees licensed by a grammar to find one that has the required sentence along its fringe (outer edges).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2.3.1. Available CFG Parsers in NLTK\n",
    "\n",
    "- Recursive descent parsing\n",
    "    - top-down algorithm\n",
    "    - pro: finds all successful parses.\n",
    "    - con: inefficient. will try all rules brute-force, even the ones that do not match the input. Goes into an infinite loop when handling a left-recursive rule.\n",
    "    - `nltk.RecursiveDescentParser()`\n",
    "\n",
    "- Shift-reduce parsing\n",
    "    - bottom-up algorithm\n",
    "    - pro: efficient. only works with the rules that match input words.\n",
    "    - con: may fail to find a legitimate parse even when there is one.\n",
    "    - `nltk.ShiftReduceParser()`\n",
    "\n",
    "- The left-corner parser\n",
    "    - a top-down parser with bottom-up filtering\n",
    "    - `nltk.LeftCornerChartParser()`: combines left-corner parsing and chart parsing\n",
    "\n",
    "- Chart parsing\n",
    "    - utilizes dynamic programming: builds and refers to well-formed substring tables (WFST)\n",
    "    - pro: efficient.\n",
    "    - con: may take up a big memory space when dealing with a long sentence.\n",
    "    - `nltk.ChartParser()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    'S -> NP VP',\n",
    "    'NP -> Det N | PRON ',\n",
    "    'NP -> Det N PP',\n",
    "    'VP -> V NP | V NP PP',\n",
    "    'PP -> P NP',\n",
    "    'Det -> \"the\" | \"a\"',\n",
    "    'N -> \"man\" | \"telescope\"',\n",
    "    'PRON -> \"I\"',\n",
    "    'V -> \"saw\"',\n",
    "    'P -> \"with\"'   \n",
    "]\n",
    "\n",
    "toy_grammar = nltk.CFG.fromstring(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (PRON I))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det the) (N man))\n",
      "    (PP (P with) (NP (Det a) (N telescope)))))\n",
      "(S\n",
      "  (NP (PRON I))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det the) (N man) (PP (P with) (NP (Det a) (N telescope))))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(toy_grammar)\n",
    "\n",
    "sent = \"I saw the man with a telescope\"\n",
    "\n",
    "for tree in parser.parse(sent.split()):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The sentence produces two possible parse trees. Thus, it is said to be structurally ambiguous -- prepositional phrase attachment ambiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "- Define grammar that covers the following sentences.\n",
    "\n",
    "    - show flights from new york to los angeles\n",
    "    - list flights from new york to los angeles\n",
    "    - show flights from new york\n",
    "    - list flights to los angeles\n",
    "    - list flights\n",
    "- Use one of the parsers to parse the sentences (i.e. test your grammar)\n",
    "\n",
    "**Note:** <br>\n",
    "- start from Verb Pharse\n",
    "- Prepositional Phrase (PP) are composed of a preposition and a Noun Phrase \n",
    "- 'los' and 'angeles' are two consecutive nouns (N) (same for new york)\n",
    "\n",
    "#### Useful reminder from above\n",
    "\n",
    "\n",
    "| __Symbol__ | __Meaning__ | __Example__ |\n",
    "|:-----------|:------------|:------------|\n",
    "| S   | sentence             | I saw the man |\n",
    "| NP  | noun phrase          | the man | \n",
    "| VP  | verb phrase          | saw the man |\n",
    "| PP  | prepositional phrase | with a telescope |\n",
    "| Det | determiner  | the |\n",
    "| N   | noun        | man |\n",
    "| V   | verb        | saw |\n",
    "| P   | preposition | with |\n",
    "\n",
    "\n",
    "- Non-Terminals: `S`, `NP`, `VP`, `PP`\n",
    "- Pre-Terminals: `Det`, `N`, `V`, `P` (Part-of-Speech Tags)\n",
    "- Terminals (Leaves): the, man, saw, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# test setenteces\n",
    "test_sents = [\n",
    "    \"show flights from new york to los angeles\", \n",
    "    \"list flights from new york to los angeles\",\n",
    "    \"show flights from new york\",\n",
    "    \"list flights to los angeles\",\n",
    "    \"list flights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    'S -> ',\n",
    "    'VP -> ',\n",
    "    'NP -> ' ,\n",
    "    'PP -> ',\n",
    "    'P -> ',\n",
    "    'N -> ' ,\n",
    "    'V -> ', \n",
    "]\n",
    "\n",
    "toy_grammar = nltk.CFG.fromstring(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.ChartParser(toy_grammar)\n",
    "\n",
    "for sent in test_sents:\n",
    "    for tree in parser.parse(sent.split()):\n",
    "        print(tree.pretty_print())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. \"Real\" Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to load a grammar written by someone else into NLTK.\n",
    "\n",
    "- run `nltk.download()`\n",
    "- go to `Models` tab\n",
    "- download `large_grammars`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading large_grammars: <urlopen error [Errno 8]\n",
      "[nltk_data]     nodename nor servname provided, or not known>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('large_grammars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "atis_grammar = nltk.data.load('grammars/large_grammars/atis.cfg')\n",
    "atis_parser = nltk.ChartParser(atis_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 5517 productions>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atis_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grammar comes with some test sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['i', 'need', 'a', 'flight', 'from', 'charlotte', 'to', 'las', 'vegas', 'that', 'makes', 'a', 'stop', 'in', 'saint', 'louis', '.'], 2085)\n"
     ]
    }
   ],
   "source": [
    "atis_test_sentences = nltk.data.load('grammars/large_grammars/atis_sentences.txt')\n",
    "atis_test_sentences = nltk.parse.util.extract_test_sentences(atis_test_sentences)\n",
    "print(atis_test_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each test sentence is a tuple of a list of sentence words and a number of possible parses with respect to the grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2085 2085\n",
      "1380 1380\n",
      "50 50\n"
     ]
    }
   ],
   "source": [
    "# let's check the number of parses our parser produces\n",
    "for sent, pnum in atis_test_sentences[:3]:\n",
    "    parses = atis_parser.parse(sent)\n",
    "    print(len(list(parses)), pnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Parse the sentences from the excercise above using **ATIS_GRAMMAR**\n",
    "- try different parsers\n",
    "- output the number of parses each sentence yields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atis_parser = nltk.LeftCornerChartParser(atis_grammar) # Add your parser\n",
    "for sent in test_sents:\n",
    "    parses = atis_parser.parse(sent.split())\n",
    "    print(len(list(parses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Probabilistic Context Free Grammars (PCFG)\n",
    "\n",
    "PCFGs are very similar to CFGs - they just have an additional probability for each production. \n",
    "\n",
    "For a given left-hand-side non-terminal, the sum of the probabilities must be 1.0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 14 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    NP -> Det N [0.6]\n",
      "    NP -> Det N PP [0.3]\n",
      "    NP -> PRON [0.1]\n",
      "    VP -> V NP [0.7]\n",
      "    VP -> V NP PP [0.3]\n",
      "    PP -> P NP [1.0]\n",
      "    Det -> 'the' [0.5]\n",
      "    Det -> 'a' [0.5]\n",
      "    N -> 'man' [0.5]\n",
      "    N -> 'telescope' [0.5]\n",
      "    PRON -> 'I' [1.0]\n",
      "    V -> 'saw' [1.0]\n",
      "    P -> 'with' [1.0]\n"
     ]
    }
   ],
   "source": [
    "weighted_rules = [\n",
    "    'S -> NP VP [1.0]',\n",
    "    'NP -> Det N [0.6]',\n",
    "    'NP -> Det N PP [0.3]',\n",
    "    'NP -> PRON [0.1]',\n",
    "    'VP -> V NP [0.7]',\n",
    "    'VP -> V NP PP [0.3]',\n",
    "    'PP -> P NP [1.0]',\n",
    "    'Det -> \"the\" [0.5]',\n",
    "    'Det -> \"a\" [0.5]',\n",
    "    'N -> \"man\" [0.5]',\n",
    "    'N -> \"telescope\" [0.5]',\n",
    "    'PRON -> \"I\" [1.0]',\n",
    "    'V -> \"saw\" [1.0]',\n",
    "    'P -> \"with\" [1.0]'   \n",
    "]\n",
    "\n",
    "toy_grammar = nltk.PCFG.fromstring(weighted_rules)\n",
    "\n",
    "print(toy_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On top of right-hand side and left-hand side, probabilistic rules have probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP\n",
      "(Det, N, PP)\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "rule = toy_grammar.productions()[2]\n",
    "print(rule.lhs())\n",
    "print(rule.rhs())\n",
    "print(rule.prob())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1. Learning Grammars from a Treebank\n",
    "\n",
    "The most important method consists of inducing a PCFG from trees in a treebank (`induce_pcfg()`). \n",
    "\n",
    "NLTK provides portion of Penn Treebank corpus, which we can utilize to induce rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading treebank: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Production rules can be extracted using `productions()` method iterating over parsed sentences in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BracketParseCorpusReader in '.../corpora/treebank/combined' (not loaded yet)>\n",
      "179360\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "\n",
    "print(treebank)\n",
    "\n",
    "productions = []\n",
    "# let's keep it small\n",
    "for item in treebank.fileids():\n",
    "    for tree in treebank.parsed_sents(item):\n",
    "        productions += tree.productions()\n",
    "    \n",
    "print(len(productions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The grammar can be induced as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import Nonterminal\n",
    "S = Nonterminal('S')\n",
    "grammar = nltk.induce_pcfg(S, productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar\n",
    "grammar.productions()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2. PCFG Parsers in NLTK\n",
    "NLTK provides several PCFG parsers:\n",
    "\n",
    "From `nltk.parse.viterbi`\n",
    "\n",
    "- ViterbiParser\n",
    "    - A bottom-up PCFG parser that uses dynamic programming to find the single most likely parse for a text. The ViterbiParser parser parses texts by filling in a “most likely constituent table”. This table records the most probable tree representation for any given span and node value. In particular, it has an entry for every start index, end index, and node value, recording the most likely subtree that spans from the start index to the end index, and has the given node value.\n",
    "\n",
    "From `nltk.parse.pchart` module\n",
    "\n",
    "- InsideChartParser\n",
    "    - A bottom-up parser for PCFG grammars that tries edges in descending order of the inside probabilities of their trees.\n",
    "    - use `beam_size = len(tokens)+1` argument\n",
    "    \n",
    "- RandomChartParser\n",
    "    - A bottom-up parser for PCFG grammars that tries edges in random order. This sorting order results in a random search strategy.\n",
    "    \n",
    "- UnsortedChartParser\n",
    "    - A bottom-up parser for PCFG grammars that tries edges in whatever order.\n",
    "\n",
    "- LongestChartParser\n",
    "    - A bottom-up parser for PCFG grammars that tries longer edges before shorter ones. This sorting order results in a type of best-first search strategy.\n",
    "\n",
    "Read about them in the [documentation](http://www.nltk.org/api/nltk.parse.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's parse one of the sentences from above using Viterbi parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "parser = nltk.ViterbiParser(grammar)\n",
    "for tree in parser.parse(\"Show me flights from New York to Los Angeles\".split()):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "- Try different parser to parse the sentences from the exercises above\n",
    "- Compare assigned probabilities\n",
    "- Compare time it takes to parse sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = \"show me flights from New York to Los Angeles\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Parser 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Parser 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Parser 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Generating Sentences\n",
    "\n",
    "Grammars can be used to generate sentences as well. This is accomplished using `generate` method.\n",
    "read [here](http://www.nltk.org/api/nltk.parse.html#module-nltk.parse.generate)\n",
    "\n",
    "arguments it takes are the following `nltk.parse.generate.generate(grammar, start=None, depth=None, n=None)`:\n",
    "\n",
    "- grammar – The Grammar used to generate sentences.\n",
    "- start – The Nonterminal, which is and NLTK object, from which to start generate sentences.\n",
    "- depth – The maximal depth of the generated tree.\n",
    "- n – The maximum number of sentences to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.parse.generate import generate\n",
    "toy_grammar = nltk.PCFG.fromstring(weighted_rules)\n",
    "for sent in generate(toy_grammar, n=10):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Generating sequences with PCFG\n",
    "To used the probabilities on the production rules while generating, you can write your function or there is this library in python called [PCFG](https://github.com/thomasbreydo/pcfg). \n",
    "```bash\n",
    "pip install pcfg\n",
    "```\n",
    "The PCFG is fully compatible with NLTK, meaning that it task the same input as for `nltk.PCFG`, but it is limited as the only parameter available is the number of sentences that you want to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcfg import PCFG\n",
    "toy_grammar = PCFG.fromstring(weighted_rules)\n",
    "for sent in toy_grammar.generate(10):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Generating sequences with PCFG (New version)\n",
    "A former NLU student released a modified version of the pcfg library implementing two missing features namely `start` and `depth`. You can find this [here](https://github.com/halixness/pcfg). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating Constituency Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Comparing Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since _constituency parser_ outputs _constituents_, parser evaluation is essentially a comparison between constituents of the reference and the automatic (hypothesis) parse trees (of the test set). Since constituents are labeled (have _syntactic categories_), the evaluation can also compare the reference and the hypothesis labels.\n",
    "\n",
    "A constituent in a hypothesis parse tree is considered correct, if there is a constituent in a reference parse tree that has the same span and label. That is:\n",
    "\n",
    "- has the same starting point\n",
    "- has the same ending point\n",
    "- has the same non-terminal symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this information we can compute precision and recall for the parser, as:\n",
    "\n",
    "$$ \\text{recall} = \\frac{\\text{\\# of correct constituents in hypothesis}}{\\text{\\# of constituents in reference}}$$\n",
    "\n",
    "$$\\text{precision} = \\frac{\\text{\\# of correct constituents in hypothesis}}{\\text{\\# of constituents in hypothesis}}$$\n",
    "\n",
    "The $F_1$ metric is computed the usual way, as:\n",
    "\n",
    "$$F_1 = \\frac{2PR}{P+R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case for the correct constituent counts we consider labels, we compute _labeled_ precision and recall. Otherwise, metrics are _unlabeled_ (i.e. we just consider the span not the label). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. PARSEVAL\n",
    "The evaluation method that implements this is known as **PARSEVAL** [(Black et al., 1991)](https://aclanthology.org/H91-1060/).\n",
    "\n",
    "The metric includes an algorithm from _caninicalization_ that removes grammar-specific information and allows comparing parsers with different grammars.\n",
    "\n",
    "The \"canonical\" implementation of **PARSEVAL** is known as [**EVALB**](https://nlp.cs.nyu.edu/evalb/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since constituents are essentially sub-trees of a sentence parse tree, while having the same label and start and end points, they might differ in their internal structure. \n",
    "\n",
    "e.g.: `((A B) C)` vs. `(A (B C))`\n",
    "\n",
    "Consequently, there is an additional metric in **PARSEVAL** that is used to account for this -- **cross-brackets** (since parse trees are represented using bracketed notation) -- which is a simple count of such cases per sentence.\n",
    "\n",
    "However, since `((A B) C)` and `(A (B C))` have different constituents, this is already reflected in precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. EVALB (PYTHON)\n",
    "There is no officially supported EVALB for python. However, there are few implementations available.\n",
    "The most easy to use it [PYEVALB](https://github.com/flyaway1217/PYEVALB).\n",
    "\n",
    "It is possible to compare two parse trees as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PYEVALB\n",
    "from PYEVALB import scorer as eval_scorer\n",
    "from PYEVALB import parser as eval_parser\n",
    "\n",
    "pt0 = \"(S (NP (PRON I)) (VP (V saw) (NP (Det the) (N man)) (PP (P with) (NP (Det a) (N telescope)))))\"\n",
    "pt1 = \"(S (NP (PRON I)) (VP (V saw) (NP (Det the) (N man) (PP (P with) (NP (Det a) (N telescope))))))\"\n",
    "\n",
    "pt0_tree = eval_parser.create_from_bracket_string(pt0)\n",
    "pt1_tree = eval_parser.create_from_bracket_string(pt1)\n",
    "\n",
    "s = eval_scorer.Scorer()\n",
    "result = s.score_trees(pt0_tree, pt1_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P: {} R: {}\".format(round(result.prec, 2), round(result.recall, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Exercise\n",
    "- Write two or more sentences of your choice.\n",
    "- Write a PCFG that models your sentences.\n",
    "- To validate your grammar, parse the sentences with a parser of your choice.\n",
    "- Then, generate 10 sentences  using a PCFG by experimenting with `nltk.parse.generate.generate` using different starting symbols and depths. Optionally, generate 10 sentences with PCFG.generate() (see section 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
