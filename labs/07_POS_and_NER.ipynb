{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part-of-Speech Tagging and Named Entity Recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recommended Reading\n",
    "\n",
    "- Dan Jurafsky and James H. Martin. [__Speech and Language Processing__ (SLP)](https://web.stanford.edu/~jurafsky/slp3/) (3rd ed. draft)\n",
    "- Steven Bird, Ewan Klein, and Edward Loper. [__Natural Language Processing with Python__ (NLTK)](https://www.nltk.org/book/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Covered Material\n",
    "\n",
    "- SLP\n",
    "    - [Chapter 8: Part-of-Speech Tagging (HMMs)](https://web.stanford.edu/~jurafsky/slp3/8.pdf)\n",
    "- NLTK\n",
    "    - [Chapter 5: Part of Speech Tagging](https://www.nltk.org/book/ch05.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Requirements\n",
    "\n",
    "- [spaCy](https://spacy.io/)\n",
    "- [NLTK](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Sequence Labeling and Classification\n",
    "[Classification](https://en.wikipedia.org/wiki/Statistical_classification) is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known.\n",
    "\n",
    "[Sequence Labeling](https://en.wikipedia.org/wiki/Sequence_labeling) is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values. It is a sub-class of [structured (output) learning](https://en.wikipedia.org/wiki/Structured_prediction), since we are predicting a *sequence* object rather than a discrete or real value predicted in classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The problem can be treated as a set of independent classification tasks, one per member of the sequence;\n",
    "- **BUT!** performance is generally improved by making the optimal label for a given element dependent on the choices of nearby elements;\n",
    "\n",
    "Due to the complexity of the model and the interrelations of predicted variables the process of prediction using a trained model and of training itself is often computationally infeasible and [approximate inference](https://en.wikipedia.org/wiki/Approximate_inference) and learning methods are used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.2. Sequence Labeling and Ngram Modeling\n",
    "[Markov Chain](https://en.wikipedia.org/wiki/Markov_chain) is a stochastic model used to describe sequences. It is the simplest [Markov Model](https://en.wikipedia.org/wiki/Markov_model). In order to make inference tractable, a process that generated the sequence is assumed to have [Markov Property](https://en.wikipedia.org/wiki/Markov_property), i.e. future states depend only on the current state, not on the events that occurred before it. (An [ngram](https://en.wikipedia.org/wiki/N-gram) [language model](https://en.wikipedia.org/wiki/Language_model) is a $(n-1)$-order Markov Model.) \n",
    "\n",
    "In Statical Language Modeling, we are modeling *observed sequences* represented as Markov Chains. Since the states of the process are *observable*, we only need to compute __transition probabilities__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Sequence Labeling, we assume that *observed sequences* (__sentences__) have been generated by a Markov Process with *unobservable* (i.e. hidden) states (__labels__), i.e. [Hidden Markov Model](https://en.wikipedia.org/wiki/Hidden_Markov_model) (__HMM__). \n",
    "Since the states of the process are hidden and the output is observable, each state has a probability distribution over the possible output tokens, i.e. __emission probabilities__. \n",
    "\n",
    "Using these two probability distributions (__transition__ and __emission__), in sequence labeling, we are *inferring* the sequence of state transitions, given a sequence of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3. The General Setting for Sequence Labeling\n",
    "\n",
    "- Create __training__ and __testing__ sets by tagging a certain amount of text by hand\n",
    "    - i.e. map each word in corpus to a tag\n",
    "- Train tagging model to extract generalizations from the annotated __training__ set\n",
    "- Evaluate the trained tagging model on the annotated __testing__ set\n",
    "- Use the trained tagging model too annotate new texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging is the process of marking up a word in a text as corresponding to a particular part of speech, based on both its definition and its context.\n",
    "\n",
    "The tag sets varies from corpus to corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1. Universal Part of Speech Tags\n",
    "\n",
    "Universal POS-Tag Set represents a simplified and unified set of part-of-speech tags, that was proposed for the standardization across corpora and languages. \n",
    "The number of defined tags varies from 12 ([Petrov et al/Google/NLTK](https://github.com/slavpetrov/universal-pos-tags)) to 17 ([Universal Dependencies/spaCy](https://universaldependencies.org/u/pos/index.html), in *Italics*).\n",
    "\n",
    "\n",
    "\n",
    "| Tag  | Meaning | English Examples |\n",
    "|:-----|:--------|:-----------------|\n",
    "| __Open Class__ |||\n",
    "| NOUN | noun (common and proper) | year, home, costs, time, Africa\n",
    "| VERB | verb (all tenses and modes) | is, say, told, given, playing, would\n",
    "| ADJ  | adjective           | new, good, high, special, big, local\n",
    "| ADV  | adverb              | really, already, still, early, now\n",
    "| *PROPN* | proper noun (split from NOUN) | Africa\n",
    "| *INTJ*  | interjection (split from X) | oh, ouch\n",
    "| __Closed Class__ |||\n",
    "| DET  | determiner, article | the, a, some, most, every, no, which\n",
    "| PRON | pronoun             | he, their, her, its, my, I, us\n",
    "| ADP  | adposition\t(prepositions and postpositions) | on, of, at, with, by, into, under\n",
    "| NUM  | numeral             | twenty-four, fourth, 1991, 14:24\n",
    "| PRT (*PART*) | particles or other function words | at, on, out, over per, that, up, with\n",
    "| CONJ | conjunction         | and, or, but, if, while, although\n",
    "| *AUX* | auxiliary (split from VERB) | have, is, should\n",
    "| *CCONJ*  | coordinating conjunction (splits CONJ) | or, and\n",
    "| *SCONJ*  | subordinating conjunction (splits CONJ) | if, while\n",
    "| __Other__ |||\n",
    "| .    | punctuation marks   | . , ; !\n",
    "| X    | other               | foreign words, typos, abbreviations: ersatz, esprit, dunno, gr8, univeristy\n",
    "| *SYM* | symbols (split from X) | $, :) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Part-of-Speech Tagging with Spacy & NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1. Part-of-Speech Tagging with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en-core-web-sm\")\n",
    "\n",
    "# un-comment the lines below, if you get 'ModuleNotFoundError'\n",
    "# import en_core_web_sm\n",
    "# nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "# let's print spaCy pipeline\n",
    "print([key for key, model in nlp.pipeline])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Oh. I have seen a man with a telescope in Antarctica.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# tokens\n",
    "print([t.text for t in doc])\n",
    "\n",
    "# Fine grained POS-tags\n",
    "print([t.tag_ for t in doc])\n",
    "\n",
    "# Coarse POS-tags (from Universal POS Tag set)\n",
    "print([t.pos_ for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2. Part-of-Speech Tagging with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "text = \"Oh. I have seen a man with a telescope in Antarctica.\"\n",
    "\n",
    "# tokenization\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "# POS-tagging (with WSJ Tags)\n",
    "print(nltk.pos_tag(tokens))\n",
    "\n",
    "# POS-tagging with Universal Tags\n",
    "print(nltk.pos_tag(tokens, tagset='universal'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.3. Training POS-Tagger with NLTK\n",
    "\n",
    "- Manually POS-tagged corpus\n",
    "- Sequence Labeling (Tagging) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.1. Corpora for POS-Tagging\n",
    "NLTK provides several corpora, most of them are POS-tagged. We will use WSJ with universal tag set (automatically converted using internal mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download treebank\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]]\n",
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "\n",
    "# WSJ POS-Tags\n",
    "print(treebank.tagged_sents()[:1])\n",
    "\n",
    "# Universal POS-Tags\n",
    "print(treebank.tagged_sents(tagset='universal')[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.2. NLTK Taggers\n",
    "\n",
    "NLTK provides several tagging algorithms, including \n",
    "\n",
    "- rule-based taggers\n",
    "    - Regular Expression Tagger: assigns tags to tokens by comparing their word strings to a series of regular expressions.\n",
    "\n",
    "- [Pre-Trained Taggers](http://www.nltk.org/api/nltk.tag.html)\n",
    "    - HunPoS\n",
    "    - Senna\n",
    "    - Stanford Tagger\n",
    "    \n",
    "- trainable taggers\n",
    "    - `Brill Tagger`: Brill's transformational rule-based tagger assigns an initial tag sequence to a text; and then applies an ordered list of transformational rules to correct the tags of individual tokens. It learns the rules from corpus.\n",
    "    - [Greedy Averaged Perceptron](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python)\n",
    "    - [TnT](http://acl.ldc.upenn.edu/A/A00/A00-1031.pdf)\n",
    "    - Hidden Markov Models\n",
    "    - Conditional Random Fields\n",
    "    - Sequential:\n",
    "        - Affix Tagger: A tagger that chooses a token's tag based on a leading or trailing substring of its word string.\n",
    "        - Ngram Tagger: A tagger that chooses a token's tag based on its word string and on the preceding _n_ word's tags.\n",
    "            - Unigram Tagger\n",
    "            - Bigram Tagger\n",
    "            - Trigram Tagger\n",
    "\n",
    "        - Classifier-based POS Tagger: A sequential tagger that uses a classifier to choose the tag for each token in a sentence.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.3. Testing a POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 3914; Train: 3132; Test: 782\n"
     ]
    }
   ],
   "source": [
    "# Prepare Training & Test Splits as 80%/20%\n",
    "import math\n",
    "\n",
    "total_size = len(treebank.tagged_sents())\n",
    "train_indx = math.ceil(total_size * 0.8)\n",
    "trn_data = treebank.tagged_sents(tagset='universal')[:train_indx]\n",
    "tst_data = treebank.tagged_sents(tagset='universal')[train_indx:]\n",
    "\n",
    "print(\"Total: {}; Train: {}; Test: {}\".format(total_size, len(trn_data), len(tst_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Rule-based POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
      "TAG  : [('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'NOUN'), (',', '.'), ('will', 'NOUN'), ('join', 'NOUN'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'NOUN'), ('a', 'DET'), ('nonexecutive', 'NOUN'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')]\n",
      "Accuracy: 0.5360\n"
     ]
    }
   ],
   "source": [
    "# rule-based tagging\n",
    "from nltk.tag import RegexpTagger\n",
    "\n",
    "# rules from NLTK adapted to Universal Tag Set & extended\n",
    "rules = [\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),   # cardinal numbers\n",
    "    (r'(The|the|A|a|An|an)$', 'DET'),   # articles\n",
    "    (r'.*able$', 'ADJ'),                # adjectives\n",
    "    (r'.*ness$', 'NOUN'),               # nouns formed from adjectives\n",
    "    (r'.*ly$', 'ADV'),                  # adverbs\n",
    "    (r'.*s$', 'NOUN'),                  # plural nouns\n",
    "    (r'.*ing$', 'VERB'),                # gerunds\n",
    "    (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "    (r'[\\.,!\\?:;\\'\"]', '.'),            # punctuation (extension) \n",
    "    (r'.*', 'NOUN')                     # nouns (default)\n",
    "]\n",
    "\n",
    "re_tagger = RegexpTagger(rules)\n",
    "\n",
    "# tagging sentences in test set\n",
    "for s in treebank.sents()[:train_indx]:\n",
    "    print(\"INPUT: {}\".format(s))\n",
    "    print(\"TAG  : {}\".format(re_tagger.tag(s)))\n",
    "    break\n",
    "    \n",
    "# evaluation\n",
    "accuracy = re_tagger.accuracy(tst_data)\n",
    "# OR re_tagger.evaluate()\n",
    "print(\"Accuracy: {:6.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Exercise 1\n",
    "\n",
    "- Extend rule-set of RegexpTagger to handle close-class words (similar to punctuation & DET):\n",
    "\n",
    "    - prepositions (ADP)\n",
    "        - in, among, of, above, etc (add as many you want)\n",
    "    - particles (PRT)\n",
    "        - to, well, up, now, not (add as many you want)\n",
    "    - pronouns (PRON)\n",
    "        - I, you, he, she, it, they, we (add as many you want)\n",
    "    - conjunctions (CONJ)\n",
    "        - and, or, but, while, when, since (add as many you want)\n",
    "\n",
    "- Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "aug_rules = [\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),   # cardinal numbers\n",
    "    (r'(The|the|A|a|An|an)$', 'DET'),   # articles\n",
    "    (r'.*able$', 'ADJ'),                # adjectives\n",
    "    (r'.*ness$', 'NOUN'),               # nouns formed from adjectives\n",
    "    (r'.*ly$', 'ADV'),                  # adverbs\n",
    "    (r'.*s$', 'NOUN'),                  # plural nouns\n",
    "    (r'.*ing$', 'VERB'),                # gerunds\n",
    "    (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "    (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "    (r'[\\.,!\\?:;\\'\"]', '.'),            # punctuation (extension) \n",
    "    (r'$', 'ADP'),                      # Add prepositions\n",
    "    (r'$', 'PRT'),                      # Add particles\n",
    "    (r'$', 'PRON'),                     # Add pronouns\n",
    "    (r'$', 'CONJ'),                     # Add conjunctions\n",
    "    (r'.*', 'NOUN')                     # nouns (default)\n",
    "\n",
    "]\n",
    "aug_re_tagger = RegexpTagger(aug_rules)\n",
    "\n",
    "# tagging sentences in test set\n",
    "for s in treebank.sents()[:train_indx]:\n",
    "    print(\"INPUT: {}\".format(s))\n",
    "    print(\"TAG  : {}\".format(aug_re_tagger.tag(s)))\n",
    "    break\n",
    "\n",
    "accuracy = aug_re_tagger.accuracy(tst_data)\n",
    "# Or = aug_re_tagger.evaluate(tst_data)\n",
    "print(\"Accuracy: {:6.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.4. Training HMM POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# training hmm on treebank\n",
    "import nltk.tag.hmm as hmm\n",
    "\n",
    "hmm_model = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_tagger = hmm_model.train(trn_data)\n",
    "\n",
    "# tagging sentences in test set\n",
    "for s in treebank.sents()[:train_indx]:\n",
    "    print(\"INPUT: {}\".format(s))\n",
    "    print(\"TAG  : {}\".format(hmm_tagger.tag(s)))\n",
    "    print(\"PATH : {}\".format(hmm_tagger.best_path(s)))\n",
    "    break\n",
    "    \n",
    "# evaluation\n",
    "accuracy = hmm_tagger.accuracy(tst_data)\n",
    "# Or = hmm_tagger.evaluate(tst_data)\n",
    "print(\"Accuracy: {:6.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Named Entity Recognition (NER)\n",
    "\n",
    "## 4.1 Shallow Parsing\n",
    "\n",
    "[Shallow Parsing](https://en.wikipedia.org/wiki/Shallow_parsing) is a kind of Sequence Labeling. The main difference from Sequence Labeling task where there is an output label (tag) per token; Shallow Parsing additionally performs __chunking__ -- segmentation of input sequence into constituents. Chunking is required to identify categories (or types) of *multi-word expressions*. In other words, in Shallow Parsing the members of a sequence are mapped to higher order units (i.e. grouped together `[['a'],['b','c']]`) and assigned a category. In this, the sequence is chucked into sub-sequences.\n",
    "For instance, we want to capture information that expressions like `\"New York\"` that consist of 2 tokens, constitute a single unit. \n",
    "\n",
    "Some examples of Sequence Labelling and Shallow Parsing tasks:\n",
    "\n",
    "- [Sequence Labeling](https://en.wikipedia.org/wiki/Sequence_labeling)\n",
    "    - [Part-of-Speech Tagging](https://en.wikipedia.org/wiki/Part-of-speech_tagging)\n",
    "- [Shallow Parsing](https://en.wikipedia.org/wiki/Shallow_parsing) (Chunking)\n",
    "    - [Phrase Chunking](https://en.wikipedia.org/wiki/Phrase_chunking)\n",
    "    - [Named-Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition) \n",
    "    - [Semantic Role Labeling](https://en.wikipedia.org/wiki/Semantic_role_labeling)\n",
    "    - Dependency [Parsing](https://en.wikipedia.org/wiki/Parsing) \n",
    "    - Discourse Parsing\n",
    "    - (Natural/Spoken) __Language Understanding__: Concept Tagging/Entity Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Encoding Segmentation Information: CoNLL Corpus Format\n",
    "\n",
    "Corpus in CoNLL format consists of series of sentences, separated by blank lines. Each sentence is encoded using a table (or \"grid\") of values, where each line corresponds to a single word, and each column corresponds to an annotation type. \n",
    "The set of columns used by CoNLL-style files can vary from corpus to corpus.\n",
    "\n",
    "```\n",
    "        Alex       B-PER\n",
    "        is         O\n",
    "        going      O\n",
    "        to         O\n",
    "        Los        B-LOC\n",
    "        Angeles    I-LOC\n",
    "        in         O\n",
    "        California B-LOC\n",
    "```\n",
    "\n",
    "- The notation scheme is used to label *multi-word* spans in token-per-line format.\n",
    "    - *Los Angeles* is a *LOCATION* concept that has 2 tokens\n",
    "- Both, prefix and suffix notations are commons: \n",
    "    - prefix: __B-LOC__\n",
    "    - suffix: __LOC-B__\n",
    "\n",
    "- Meaning of Prefixes (IOB tags)\n",
    "    - __I__ for (__I__)nside of span\n",
    "    - __O__ for (__O__)utside of span (no prefix or suffix, just `O`)\n",
    "    - __B__ for (__B__)eginning of span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Sentence chunking and NER with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a reasonably long document\n",
    "\n",
    "# The original document can be found at https://www.reuters.com/technology/nvidia-chases-30-billion-custom-chip-market-with-new-unit-sources-2024-02-09/\n",
    "\n",
    "document = \"Nvidia (NVDA.O), opens new tab is building a new business unit focused on designing bespoke chips for cloud computing firms and others, including advanced artificial intelligence (AI) processors, nine sources familiar with its plans told Reuters. The dominant global designer and supplier of AI chips aims to capture a portion of an exploding market for custom AI chips and shield itself from the growing number of companies pursuing alternatives to its products. The Santa Clara, California-based company controls about 80% of high-end AI chip market, a position that has sent its stock market value up 40% so far this year to $1.73 trillion after it more than tripled in 2023. Nvidia\\'s customers, which include ChatGPT creator OpenAI, Microsoft (MSFT.O), opens new tab, Alphabet (GOOGL.O), opens new tab and Meta Platforms (META.O), opens new tab, have raced to snap up the dwindling supply of its chips to compete in the fast-emerging generative AI sector. Its H100 and A100 chips serve as a generalized, all-purpose AI processor for many of those major customers. But the tech companies have started to develop their own internal chips for specific needs. Doing so helps reduce energy consumption, and potentially can shrink the cost and time to design. Nvidia is now attempting to play a role in helping these companies develop custom AI chips that have flowed to rival firms such as Broadcom (AVGO.O), opens new tab and Marvell Technology (MRVL.O), opens new tab, said the sources, who declined to be identified because they were not authorized to speak publicly. \\\"If you're really trying to optimize on things like power, or optimize on cost for your application, you can't afford to go drop an H100 or A100 in there,\\\" Greg Reichow, general partner at venture capital firm Eclipse Ventures said in an interview. \\\" You want to have the exact right mixture of compute and just the kind of compute that you need.\\\" Nvidia does not disclose H100 prices, which are higher than for the prior-generation A100, but each chip can sell for $16,000 to $100,000 depending on volume and other factors. Meta plans to bring its total stock to 350,000 H100s this year. Nvidia officials have met with representatives from Amazon.com (AMZN.O), opens new tab, Meta, Microsoft, Google and OpenAI to discuss making custom chips for them, two sources familiar with the meetings said. Beyond data center chips, Nvidia has pursued telecom, automotive and video game customers. Nvidia shares rose 2.75% after the Reuters report, helping lift chip stocks overall. Marvell shares dropped 2.78%. In 2022, Nvidia said it would let third-party customers integrate some of its proprietary networking technology with their own chips. It has said nothing about the program since, and Reuters is reporting its wider ambitions for the first time. A Nvidia spokesperson declined to comment beyond the company\\'s 2022 announcement. Dina McKinney, a former Advanced Micro Devices (AMD.O), opens new tab and Marvell executive, heads Nvidia\\'s custom unit and her team\\'s goal is to make its technology available for customers in cloud, 5G wireless, video games and automotives, a LinkedIn profile said. Those mentions were scrubbed and her title changed after Reuters sought comment from Nvidia. Amazon, Google, Microsoft, Meta and OpenAI declined to comment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the spaCy model for the English language and process our document\n",
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We chuck the document into sentences with the spaCy\n",
    "for s_id, sent in enumerate(doc.sents):\n",
    "    print(s_id+1, \":\", sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sentence we print the entities\n",
    "for s_id, sent in enumerate(doc.sents):\n",
    "    ents = [(entity.text, entity.label_) for entity in sent.ents]\n",
    "    print(s_id+1, \":\", ents)\n",
    "# or if you want the same info but with IOB tags\n",
    "for s_id, sent in  enumerate(doc.sents):\n",
    "    print(s_id+1, \":\", [w.ent_iob_ + \"-\" + w.ent_type_ if w.ent_iob_ != \"O\" else w.ent_iob_ for w in sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Train a NER model with NLTK\n",
    "We will train a Hidden Markov Model. We will use conll2002 as training and testing corpus which is in the Spanish language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('conll2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2002\n",
    "print(len(conll2002.tagged_sents()))\n",
    "print(conll2002._chunk_types)\n",
    "print(conll2002.sents('esp.train')[0])\n",
    "print(conll2002.tagged_sents('esp.train')[0])\n",
    "print(conll2002.chunked_sents('esp.train')[0])\n",
    "print(conll2002.iob_sents('esp.train')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.tag.hmm as hmm\n",
    "\n",
    "hmm_model = hmm.HiddenMarkovModelTrainer()\n",
    "\n",
    "print(conll2002.iob_sents('esp.train')[0])\n",
    "\n",
    "# let's get only word and iob-tag\n",
    "trn_sents = [[(text, iob) for text, pos, iob in sent] for sent in conll2002.iob_sents('esp.train')]\n",
    "print(trn_sents[0])\n",
    "\n",
    "tst_sents = [[(text, iob) for text, pos, iob in sent] for sent in conll2002.iob_sents('esp.testa')]\n",
    "\n",
    "hmm_ner = hmm_model.train(trn_sents)\n",
    "    \n",
    "# evaluation\n",
    "accuracy = hmm_ner.accuracy(tst_sents)\n",
    "# Evaluation at Token LEVEL!!!\n",
    "print(\"Accuracy: {:6.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate a shallow parsing model we have to evaluate it at **chunk level**. For this, we can use the evaluate function of conll script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "\n",
    "from conll import evaluate\n",
    "# for nice tables\n",
    "import pandas as pd\n",
    "\n",
    "# getting references (try to replace testa with testb)\n",
    "\n",
    "refs = [[(text, iob) for text, pos, iob in sent] for sent in conll2002.iob_sents('esp.testa')]\n",
    "print(refs[0])\n",
    "# getting hypotheses\n",
    "hyps = [hmm_ner.tag(s) for s in conll2002.sents('esp.testa')]\n",
    "print(hyps[0])\n",
    "results = evaluate(refs, hyps)\n",
    "\n",
    "# The total F1 is a micro-F1\n",
    "\n",
    "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "pd_tbl.round(decimals=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 \n",
    "Evaluate spaCy NER model on the conll2002 corpus and compare the results with NLTK trained model.\n",
    "\n",
    "To do this you have to:\n",
    "\n",
    "- Load the spaCy model for the Spanish language (`es_core_news_sm`) or you can try with larger models\n",
    "- Retrieve spaCy prediction with IOB schema\n",
    "- Evaluate the model with the conll script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "# We overwrite the spaCy tokenizer with a custom one, that split by whitespace only. However, it is a suboptimal solution.\n",
    "nlp.tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# getting references\n",
    "refs = []\n",
    "# Use spaCy model for predicting the Named Entities\n",
    "hyps = []\n",
    "\n",
    "\n",
    "results = evaluate(refs, hyps)\n",
    "# The total F1 is a micro-F1\n",
    "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lab Exercise: Comparative Evaluation of NLTK Tagger and Spacy Tagger\n",
    "\n",
    "Train and evaluate NgramTagger\n",
    "- experiment with different tagger parameters\n",
    "- some of them have *cut-off*\n",
    "\n",
    "Evaluate `spacy` POS-tags on the same test set\n",
    "- create mapping from spacy to NLTK POS-tags \n",
    "    - SPACY list https://universaldependencies.org/u/pos/index.html\n",
    "    - NLTK list https://github.com/slavpetrov/universal-pos-tags\n",
    "- convert output to the required format (see format above)\n",
    "    - flatten into a list\n",
    "- evaluate using `accuracy` from `nltk.metrics` \n",
    "    - [link](https://www.nltk.org/_modules/nltk/metrics/scores.html#accuracy)\n",
    "        \n",
    "**Dataset**: treebank <br>\n",
    "**Expected output**: NLTK: Accuracy SPACY: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# See above for further details\n",
    "mapping_spacy_to_NLTK = {\n",
    "    \"ADJ\": \"ADJ\",\n",
    "    \"ADP\": \"ADP\",\n",
    "    \"ADV\": \"ADV\",\n",
    "    \"AUX\": \"VERB\",\n",
    "    \"CCONJ\": \"CONJ\",\n",
    "    \"DET\": \"DET\",\n",
    "    \"INTJ\": \"X\",\n",
    "    \"NOUN\": \"NOUN\",\n",
    "    \"NUM\": \"NUM\",\n",
    "    \"PART\": \"PRT\",\n",
    "    \"PRON\": \"PRON\",\n",
    "    \"PROPN\": \"NOUN\",\n",
    "    \"PUNCT\": \".\",\n",
    "    \"SCONJ\": \"CONJ\",\n",
    "    \"SYM\": \"X\",\n",
    "    \"VERB\": \"VERB\",\n",
    "    \"X\": \"X\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "nlp = en_core_web_sm.load()\n",
    "# We overwrite the spacy tokenizer with a custom one, that split by whitespace only\n",
    "nlp.tokenizer = Tokenizer(nlp.vocab) # Tokenize by whitespace\n",
    "# Sanity check\n",
    "for id_sent, sent in enumerate(treebank.sents()):\n",
    "    doc = nlp(\" \".join(sent))\n",
    "    if len([x.text for x in doc]) != len(sent):\n",
    "        print(id_sent, sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
